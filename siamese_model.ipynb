{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "\n",
    "from keras import regularizers\n",
    "from keras.layers import Flatten\n",
    "import collections\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Conv1D,Dense,Dropout,MaxPooling1D,ZeroPadding1D, Flatten,BatchNormalization,Lambda\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doc2Vec 모델 불러오기\n",
    "p2v_model = doc2vec.Doc2Vec.load('p2v_128_all_1.model')\n",
    "# 데이터 불러오기\n",
    "data=pd.read_csv('all_after_filter.csv')\n",
    "person_id=data['PERSON_ID'].unique()\n",
    "data.sort_values('RECU_FR_DT',inplace=True)\n",
    "data.drop(columns=['KEY_SEQ','RECU_FR_DT','MAIN_ICDnorm'],inplace=True)\n",
    "person_id=person_id.tolist()\n",
    "train_label_df=pd.read_csv('label_train1.csv')\n",
    "test_label_df=pd.read_csv('label_test1.csv')\n",
    "train_label_df.iloc[:,2]=train_label_df.iloc[:,2].astype('float32')\n",
    "test_label_df.iloc[:,2]=test_label_df.iloc[:,2].astype('float32')\n",
    "person_doc_dict={key:value for value,key in enumerate(person_id)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 visit embedding 후 metrics만들기\n",
    "embedding=np.zeros(shape=[len(person_id),480,128],dtype='float32')\n",
    "def get_vec(person_id,train_df):\n",
    "    person2vec=np.zeros(shape=[480,128])\n",
    "    features=['SEX','AGE_GROUP','CLA_ITE','GNL_NM_CD','SICK_SYMnorm']\n",
    "    this_person_record=train_df[train_df.PERSON_ID==person_id]\n",
    "    for index,record in enumerate(this_person_record[features].iterrows()):\n",
    "        thisrec=','.join('%s' %con for con in record[1].tolist())\n",
    "        thisvec=p2v_model.infer_vector(thisrec.split(','))\n",
    "        person2vec[index]=thisvec\n",
    "        person2vec.astype('float32')\n",
    "    return person2vec\n",
    "\n",
    "for i,thisperson in enumerate(person_id):\n",
    "    embedding[i]=get_vec(thisperson,train_df=data)\n",
    "np.save('embedding_metrix_1',embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding=np.load('embedding_metrix_1.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train에서 검증셋 추출\n",
    "from sklearn.model_selection import train_test_split\n",
    "new_train_label_df, cv_label_df =train_test_split(train_label_df, test_size=0.25, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((120000, 3), (40000, 3), (40000, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_label_df.shape ,cv_label_df.shape, test_label_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity learning을 진행하기 위한 데이터 셋 만들기\n",
    "class CSV_dataset():\n",
    "    def __init__(self, label_df, person_doc_dict, embedding):\n",
    "        super(CSV_dataset, self).__init__()\n",
    "        self.label_df = label_df\n",
    "        self.person_doc_dict = person_doc_dict\n",
    "        self.embedding = embedding\n",
    "    def __getitem__(self, item):\n",
    "        person_1 = self.label_df.iloc[item, 0]\n",
    "        person_2 = self.label_df.iloc[item, 1]\n",
    "        person_1_id=self.person_doc_dict[person_1]\n",
    "        person_2_id=self.person_doc_dict[person_2]\n",
    "        person_1_vec =self.embedding[person_1_id]\n",
    "        person_2_vec =self.embedding[person_2_id]\n",
    "        similarity = self.label_df.iloc[item, 2]\n",
    "        \n",
    "        return person_1_vec, person_2_vec, similarity\n",
    "    def __len__(self):\n",
    "        return len(self.label_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = CSV_dataset(new_train_label_df, person_doc_dict, embedding)\n",
    "train_data_left =[]\n",
    "train_data_right = []\n",
    "train_label = []\n",
    "\n",
    "for i in range(10000):\n",
    "    r = train_ds.__getitem__(i)\n",
    "    train_data_left.append(r[0])\n",
    "    train_data_right.append(r[1])\n",
    "    train_label.append([r[2]])\n",
    "    \n",
    "train_data_left = np.array(train_data_left)\n",
    "train_data_right = np.array(train_data_right)\n",
    "train_label = np.array(train_label)                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_ds = CSV_dataset(cv_label_df, person_doc_dict, embedding)\n",
    "cv_data_left =[]\n",
    "cv_data_right = []\n",
    "cv_label = []\n",
    "\n",
    "\n",
    "for i in range(2000):\n",
    "    r = cv_ds.__getitem__(i)\n",
    "    cv_data_left.append(r[0])\n",
    "    cv_data_right.append(r[1])\n",
    "    cv_label.append([r[2]])\n",
    "\n",
    "cv_data_left = np.array(cv_data_left)\n",
    "cv_data_right = np.array(cv_data_right)\n",
    "cv_label = np.array(cv_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = CSV_dataset(test_label_df, person_doc_dict, embedding)\n",
    "test_data_left =[]\n",
    "test_data_right = []\n",
    "test_label = []\n",
    "\n",
    "for i in range(2000):\n",
    "    r = test_ds.__getitem__(i)\n",
    "    test_data_left.append(r[0])\n",
    "    test_data_right.append(r[1])\n",
    "    test_label.append([r[2]])\n",
    "\n",
    "\n",
    "test_data_left = np.array(test_data_left)\n",
    "test_data_right = np.array(test_data_right)\n",
    "test_label = np.array(test_label)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 vactor 사이에 L2 거리구하기\n",
    "def euclidean_distance(vectors):\n",
    "    # unpack the vectors into separate lists\n",
    "    (featsA, featsB) = vectors\n",
    "    # compute the sum of squared distances between the vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,\n",
    "        keepdims=True)\n",
    "    # return the euclidean distance between the vectors\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 샴네트워크"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the shape of the inputs for our network\n",
    "IMG_SHAPE = (480, 128)\n",
    "# specify the batch size and number of epochs\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 100\n",
    "# define the path to the base output directory\n",
    "BASE_OUTPUT = \"output\"\n",
    "\n",
    "MODEL_PATH = os.path.sep.join([BASE_OUTPUT,\n",
    "\t\"contrastive_siamese_model\"])\n",
    "PLOT_PATH = os.path.sep.join([BASE_OUTPUT,\n",
    "\t\"contrastive_plot.png\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그림 그리기\n",
    "def plot_training(H, plotPath):\n",
    "    plt.style.use(\"ggplot\")\n",
    "    plt.figure()\n",
    "    plt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
    "    plt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Epoch #\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend(loc=\"lower left\")\n",
    "    plt.savefig(plotPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두 환자의 representation vector를 얻기위한 model 생성\n",
    "def build_siamese_model(inputShape):\n",
    "    inputs = Input(inputShape)\n",
    "    x = Conv1D(64, 10, padding=\"same\", activation=\"relu\",kernel_regularizer = regularizers.l2(0.001))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(64, 7, padding=\"same\", activation=\"relu\",kernel_regularizer = regularizers.l2(0.001))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(64, 5, padding=\"same\", activation=\"relu\",kernel_regularizer = regularizers.l2(0.001))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, 10, padding=\"same\", activation=\"relu\",kernel_regularizer = regularizers.l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D( )(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "\n",
    "    x = Conv1D(128, 7, padding=\"same\", activation=\"relu\",kernel_regularizer = regularizers.l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, 5, padding=\"same\", activation=\"relu\",kernel_regularizer = regularizers.l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    x = Conv1D(128, 5, padding=\"same\", activation=\"relu\",kernel_regularizer = regularizers.l2(0.001))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D()(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    \n",
    "    outputs = Flatten()(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss fuction 만들기\n",
    "def contrastive_loss(y, preds, margin=1):\n",
    "    y = tf.cast(y, preds.dtype)\n",
    "    squaredPreds = K.square(preds)\n",
    "    squaredMargin = K.square(K.maximum(margin - preds, 0))\n",
    "    loss = K.mean(y * squaredPreds + (1 - y) * squaredMargin)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgA = Input(shape=IMG_SHAPE)\n",
    "imgB = Input(shape=IMG_SHAPE)\n",
    "# Feature vector 만들기\n",
    "featureExtractor = build_siamese_model(IMG_SHAPE)\n",
    "featsA = featureExtractor(imgA)\n",
    "featsB = featureExtractor(imgB)\n",
    "\n",
    "# 두 feature vector간 거리구하기\n",
    "distance = Lambda(euclidean_distance)([featsA,featsB])\n",
    "model = Model(inputs=[imgA, imgB], outputs=distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "[INFO] training model...\n",
      "Epoch 1/100\n",
      "313/313 [==============================] - 118s 356ms/step - loss: 1634.8546 - val_loss: 24.4098\n",
      "Epoch 2/100\n",
      "313/313 [==============================] - 100s 318ms/step - loss: 529.1856 - val_loss: 3.3309\n",
      "Epoch 3/100\n",
      "313/313 [==============================] - 100s 319ms/step - loss: 290.0895 - val_loss: 2.1554\n",
      "Epoch 4/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 147.9224 - val_loss: 1.5445\n",
      "Epoch 5/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 69.1329 - val_loss: 1.0436\n",
      "Epoch 6/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 28.4749 - val_loss: 0.9236\n",
      "Epoch 7/100\n",
      "313/313 [==============================] - 99s 315ms/step - loss: 10.1725 - val_loss: 0.9350\n",
      "Epoch 8/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 3.2902 - val_loss: 1.0026\n",
      "Epoch 9/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 1.2150 - val_loss: 1.0462\n",
      "Epoch 10/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.8551 - val_loss: 1.0532\n",
      "Epoch 11/100\n",
      "313/313 [==============================] - 99s 315ms/step - loss: 0.8398 - val_loss: 1.0504\n",
      "Epoch 12/100\n",
      "313/313 [==============================] - 102s 326ms/step - loss: 0.8351 - val_loss: 1.0446\n",
      "Epoch 13/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.8334 - val_loss: 1.0388\n",
      "Epoch 14/100\n",
      "313/313 [==============================] - 104s 332ms/step - loss: 0.8294 - val_loss: 1.0318\n",
      "Epoch 15/100\n",
      "313/313 [==============================] - 101s 321ms/step - loss: 0.8252 - val_loss: 1.0250\n",
      "Epoch 16/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.8210 - val_loss: 1.0126\n",
      "Epoch 17/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.8129 - val_loss: 1.0007\n",
      "Epoch 18/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.8076 - val_loss: 0.9878\n",
      "Epoch 19/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.7982 - val_loss: 0.9719\n",
      "Epoch 20/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.7915 - val_loss: 0.9568\n",
      "Epoch 21/100\n",
      "313/313 [==============================] - 102s 325ms/step - loss: 0.7803 - val_loss: 0.9406\n",
      "Epoch 22/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.7679 - val_loss: 0.9206\n",
      "Epoch 23/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.7561 - val_loss: 0.8967\n",
      "Epoch 24/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.7408 - val_loss: 0.8786\n",
      "Epoch 25/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.7236 - val_loss: 0.8541\n",
      "Epoch 26/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.7061 - val_loss: 0.8253\n",
      "Epoch 27/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.6845 - val_loss: 0.7901\n",
      "Epoch 28/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.6626 - val_loss: 0.7678\n",
      "Epoch 29/100\n",
      "313/313 [==============================] - 99s 317ms/step - loss: 0.6375 - val_loss: 0.7302\n",
      "Epoch 30/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.6096 - val_loss: 0.6971\n",
      "Epoch 31/100\n",
      "313/313 [==============================] - 102s 326ms/step - loss: 0.5853 - val_loss: 0.6658\n",
      "Epoch 32/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.5530 - val_loss: 0.6219\n",
      "Epoch 33/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.5231 - val_loss: 0.5732\n",
      "Epoch 34/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.4900 - val_loss: 0.5529\n",
      "Epoch 35/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.4582 - val_loss: 0.5241\n",
      "Epoch 36/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.4256 - val_loss: 0.4959\n",
      "Epoch 37/100\n",
      "313/313 [==============================] - 99s 315ms/step - loss: 0.3919 - val_loss: 0.4484\n",
      "Epoch 38/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.3674 - val_loss: 0.4370\n",
      "Epoch 39/100\n",
      "313/313 [==============================] - 99s 317ms/step - loss: 0.3451 - val_loss: 0.4039\n",
      "Epoch 40/100\n",
      "313/313 [==============================] - 100s 320ms/step - loss: 0.3195 - val_loss: 0.3812\n",
      "Epoch 41/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.2984 - val_loss: 0.3767\n",
      "Epoch 42/100\n",
      "313/313 [==============================] - 98s 315ms/step - loss: 0.2908 - val_loss: 0.3645\n",
      "Epoch 43/100\n",
      "313/313 [==============================] - 99s 316ms/step - loss: 0.2791 - val_loss: 0.3444\n",
      "Epoch 44/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.2717 - val_loss: 0.3248\n",
      "Epoch 45/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.2633 - val_loss: 0.3220\n",
      "Epoch 46/100\n",
      "313/313 [==============================] - 99s 316ms/step - loss: 0.2602 - val_loss: 0.3042\n",
      "Epoch 47/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.2503 - val_loss: 0.3231\n",
      "Epoch 48/100\n",
      "313/313 [==============================] - 106s 337ms/step - loss: 0.2456 - val_loss: 0.3012\n",
      "Epoch 49/100\n",
      "313/313 [==============================] - 101s 324ms/step - loss: 0.2524 - val_loss: 0.3087\n",
      "Epoch 50/100\n",
      "313/313 [==============================] - 101s 323ms/step - loss: 0.2530 - val_loss: 0.3191\n",
      "Epoch 51/100\n",
      "313/313 [==============================] - 105s 333ms/step - loss: 0.2451 - val_loss: 0.3109\n",
      "Epoch 52/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.2439 - val_loss: 0.2972\n",
      "Epoch 53/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.2510 - val_loss: 0.3116\n",
      "Epoch 54/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2484 - val_loss: 0.3026\n",
      "Epoch 55/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.2560 - val_loss: 0.3378\n",
      "Epoch 56/100\n",
      "313/313 [==============================] - 99s 315ms/step - loss: 0.2535 - val_loss: 0.3078\n",
      "Epoch 57/100\n",
      "313/313 [==============================] - 100s 318ms/step - loss: 0.2502 - val_loss: 0.2989\n",
      "Epoch 58/100\n",
      "313/313 [==============================] - 101s 323ms/step - loss: 0.2586 - val_loss: 0.3125\n",
      "Epoch 59/100\n",
      "313/313 [==============================] - 100s 319ms/step - loss: 0.2571 - val_loss: 0.2985\n",
      "Epoch 60/100\n",
      "313/313 [==============================] - 100s 320ms/step - loss: 0.2560 - val_loss: 0.3185\n",
      "Epoch 61/100\n",
      "313/313 [==============================] - 100s 319ms/step - loss: 0.2591 - val_loss: 0.3233\n",
      "Epoch 62/100\n",
      "313/313 [==============================] - 99s 317ms/step - loss: 0.2523 - val_loss: 0.3190\n",
      "Epoch 63/100\n",
      "313/313 [==============================] - 99s 317ms/step - loss: 0.2565 - val_loss: 0.3287\n",
      "Epoch 64/100\n",
      "313/313 [==============================] - 99s 315ms/step - loss: 0.2540 - val_loss: 0.3014\n",
      "Epoch 65/100\n",
      "313/313 [==============================] - 99s 316ms/step - loss: 0.2478 - val_loss: 0.3238\n",
      "Epoch 66/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.2579 - val_loss: 0.3094\n",
      "Epoch 67/100\n",
      "313/313 [==============================] - 105s 335ms/step - loss: 0.2491 - val_loss: 0.3084\n",
      "Epoch 68/100\n",
      "313/313 [==============================] - 99s 315ms/step - loss: 0.2477 - val_loss: 0.2984\n",
      "Epoch 69/100\n",
      "313/313 [==============================] - 99s 316ms/step - loss: 0.2435 - val_loss: 0.2913\n",
      "Epoch 70/100\n",
      "313/313 [==============================] - 101s 321ms/step - loss: 0.2434 - val_loss: 0.3169\n",
      "Epoch 71/100\n",
      "313/313 [==============================] - 99s 315ms/step - loss: 0.2486 - val_loss: 0.2981\n",
      "Epoch 72/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.2479 - val_loss: 0.3019\n",
      "Epoch 73/100\n",
      "313/313 [==============================] - 99s 315ms/step - loss: 0.2434 - val_loss: 0.3018\n",
      "Epoch 74/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.2388 - val_loss: 0.2759\n",
      "Epoch 75/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.2380 - val_loss: 0.2907\n",
      "Epoch 76/100\n",
      "313/313 [==============================] - 100s 320ms/step - loss: 0.2419 - val_loss: 0.2879\n",
      "Epoch 77/100\n",
      "313/313 [==============================] - 98s 314ms/step - loss: 0.2356 - val_loss: 0.2826\n",
      "Epoch 78/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2324 - val_loss: 0.3023\n",
      "Epoch 79/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2344 - val_loss: 0.2829\n",
      "Epoch 80/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2417 - val_loss: 0.2757\n",
      "Epoch 81/100\n",
      "313/313 [==============================] - 97s 309ms/step - loss: 0.2275 - val_loss: 0.2756\n",
      "Epoch 82/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2286 - val_loss: 0.2910\n",
      "Epoch 83/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.2259 - val_loss: 0.2857\n",
      "Epoch 84/100\n",
      "313/313 [==============================] - 106s 339ms/step - loss: 0.2301 - val_loss: 0.2796\n",
      "Epoch 85/100\n",
      "313/313 [==============================] - 100s 318ms/step - loss: 0.2314 - val_loss: 0.2812\n",
      "Epoch 86/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2264 - val_loss: 0.2767\n",
      "Epoch 87/100\n",
      "313/313 [==============================] - 106s 338ms/step - loss: 0.2297 - val_loss: 0.2717\n",
      "Epoch 88/100\n",
      "313/313 [==============================] - 98s 311ms/step - loss: 0.2236 - val_loss: 0.2895\n",
      "Epoch 89/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2376 - val_loss: 0.2722\n",
      "Epoch 90/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2306 - val_loss: 0.2852\n",
      "Epoch 91/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2254 - val_loss: 0.2818\n",
      "Epoch 92/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2324 - val_loss: 0.2758\n",
      "Epoch 93/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2244 - val_loss: 0.2868\n",
      "Epoch 94/100\n",
      "313/313 [==============================] - 102s 326ms/step - loss: 0.2232 - val_loss: 0.2968\n",
      "Epoch 95/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2340 - val_loss: 0.2846\n",
      "Epoch 96/100\n",
      "313/313 [==============================] - 97s 310ms/step - loss: 0.2231 - val_loss: 0.2805\n",
      "Epoch 97/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2279 - val_loss: 0.2546\n",
      "Epoch 98/100\n",
      "313/313 [==============================] - 97s 311ms/step - loss: 0.2235 - val_loss: 0.2702\n",
      "Epoch 99/100\n",
      "313/313 [==============================] - 98s 312ms/step - loss: 0.2184 - val_loss: 0.2490\n",
      "Epoch 100/100\n",
      "313/313 [==============================] - 98s 313ms/step - loss: 0.2166 - val_loss: 0.2621\n",
      "[INFO] plotting training history...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"[INFO] compiling model...\")\n",
    "opt = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "model.compile(loss=contrastive_loss, optimizer=opt)\n",
    "# model train\n",
    "print(\"[INFO] training model...\")\n",
    "history = model.fit(\n",
    "    [train_data_left, train_data_right ], train_label[:],\n",
    "    validation_data=([cv_data_left, cv_data_right], cv_label[:]),\n",
    "    batch_size=32,\n",
    "    epochs=100)\n",
    "# 그래프 그리기\n",
    "print(\"[INFO] plotting training history...\")\n",
    "plot_training(history, PLOT_PATH)\n",
    "# weights 저장\n",
    "model.save_weights('sam_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
